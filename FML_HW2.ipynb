{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruiqi-rachel-wang/MachineLearning-class/blob/main/FML_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKXNjhiaxxUi"
      },
      "source": [
        "# Fundamentals of Machine Learning (CSCI-UA.473)\n",
        "\n",
        "## Homework 2\n",
        "### Due: October 26th, 2023 at 11:59PM\n",
        "\n",
        "### Name: Ruiqi Wang\n",
        "### Email: rw2799@nyu.edu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-Qegkzl4WOe",
        "outputId": "12aec6be-bdde-4a43-efd9-f6a475eb77f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVL473j7W0CB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## Use the same dataset that was released with HW1\n",
        "data = pd.read_csv('/content/FML2023_HW1_Dataset.csv')\n",
        "# Separate the features, target values, and feature names\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target'].values\n",
        "X =X.to_numpy()\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD2ESfcW7ai7"
      },
      "source": [
        "### Question 1: Maximum Likelihood Estimation (MLE) vs Maximum A Posteriori (MAP) (25 points)\n",
        "\n",
        "In Homework 1, we performed linear and ridge regression. To summarize:\n",
        "\n",
        "In Linear regression,\n",
        "\n",
        "$$\\beta = \\arg\\min_{\\beta}\\sum\\left(y_i - \\left(\\beta_0 + \\beta_1 x_{1i} +, \\ldots, + \\beta_px_{p i}\\right)\\right)^2$$\n",
        "\n",
        "\n",
        "* $J(\\beta)$ is the cost function.\n",
        "* $\\beta_0,\\ldots,\\beta_p$ are the coefficients for the features.\n",
        "* $x_{1i}$ represents the values of the feature for the i-th observation.\n",
        "* $y_i$ is the target value for the i-th observation.\n",
        "\n",
        "For ridge regression\n",
        "\n",
        "$$J(\\beta) = \\sum\\left(y_i - \\left(\\beta_0 + \\beta_1 x_{1i} +, \\ldots, + \\beta_px_{p i}\\right)\\right)^2 + \\lambda \\cdot \\sum \\beta_i^2$$\n",
        "\n",
        "* $\\lambda$ is the regularization hyper-parameter.\n",
        "\n",
        "**Task 1.1 (5 points)** Linear regression embodies Maximum Likelihood Estimation (MLE). Show that a closed form expression is $$\\beta = (\\mathbf{A}^\\top \\mathbf{A})^{-1}\\mathbf{A}^\\top \\mathbf{Y}$$ where $\\mathbf{A} = [X_1,\\ldots,X_n]$ and $\\mathbf{Y} = [Y_1,\\ldots,Y_n]$.\n",
        "\n",
        "**Task 1.2 (5 points)**: Ridge regression embodies Maximum A Posteriori (MAP), wherein the regularizer serves as the prior. Show that a closed form expression for the ridge estimator is $$\\beta = (\\mathbf{A}^\\top \\mathbf{A} + \\lambda I)^{-1}\\mathbf{A}^\\top \\mathbf{Y}$$ where $\\mathbf{A} = [X_1,\\ldots,X_n]$ and $\\mathbf{Y} = [Y_1,\\ldots,Y_n]$.\n",
        "\n",
        "**Task 1.3 Implementation (10 points):** Fill in the code below to differentiate between MLE and MAP.\n",
        "\n",
        "**Task 1.4 (5 points):**\n",
        "* Do MLE and MAP yield distinct solutions as the sample size tends to infinity? Explain your answer.\n",
        "\n",
        "* Will the impact of prior be greater with a small or large sample size, and what is the underlying rationale for this phenomenon?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1\n",
        "\n",
        "set gradient to zero, then $∇J(\\beta)=0$, for each β $∂J/∂β=-2∑x_{ji}(y_i-(β_0+β_1x_{1i}...))$, so $A^TAβ=A^TY$, $β=(A^TA)^{-1}A^TY$\n",
        "\n",
        "1.2\n",
        "\n",
        "set gradient to zero, then $∇J(\\beta)=0$, for each β $∂J/∂β=-2∑x_{ji}(y_i-(β_0+β_1x_{1i}...))+2λβ_j$, so $A^TAβ+λIβ=A^TY$, $β=(A^TA+λI)^{-1}A^TY$\n",
        "\n",
        "1.4\n",
        "\n",
        "It will yield same solution since the impact of the prior in MAP diminished and the solution of both tend to converge.\n",
        "\n",
        "Small sample size. It can potentially preventing overfitting. As size grows, relative infulence of proior reduces, making solutions more alike."
      ],
      "metadata": {
        "id": "PumwPxe9yDFl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oleMgs0V7Zsl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af261b1f-06ab-4519-9937-263d09cb21e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE using MLE: 2900.1936284934827\n"
          ]
        }
      ],
      "source": [
        "def mle_linear_regression(X, y):\n",
        "  X_bias = np.c_[np.ones(X.shape[0]), X]\n",
        "  theta_mle = np.linalg.inv(X_bias.T @ X_bias) @ X_bias.T @ y\n",
        "  return theta_mle\n",
        "\n",
        "# Calculate MLE estimates without bias\n",
        "theta_mle = mle_linear_regression(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_preds = np.dot(np.c_[np.ones(X_test.shape[0]), X_test], theta_mle)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse_mle = np.mean((y_test - y_preds)**2)\n",
        "print(f\"MSE using MLE: {mse_mle}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqvfD-8uF-Jl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87955d9c-8a4e-477a-fe4a-bcf4b2901988"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE using MAP: 2882.2901804060125\n"
          ]
        }
      ],
      "source": [
        "def map_linear_regression(X, y, lambda_reg):\n",
        "  X_bias = np.c_[np.ones(X.shape[0]), X]\n",
        "  I = np.identity(X_bias.shape[1])\n",
        "  I[0, 0] = 0\n",
        "  theta_map = np.linalg.inv(X_bias.T @ X_bias + lambda_reg * I) @ X_bias.T @ y\n",
        "  return theta_map\n",
        "\n",
        "# Set the regularization parameter (lambda)\n",
        "lambda_reg = 0.01\n",
        "theta_map = map_linear_regression(X_train, y_train, lambda_reg)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_preds = np.dot(np.c_[np.ones(X_test.shape[0]), X_test], theta_map)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse_map = np.mean((y_test - y_preds)**2)\n",
        "print(f\"MSE using MAP: {mse_map}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwH8gND4XGvE"
      },
      "source": [
        "### Question 2: Classification with imbalanced dataset (20 points)\n",
        "\n",
        "We are creating an imbalanced version of the target variable for the Z dataset. An imbalanced dataset means that one class is much more frequent than the other class. In our case, we will consider the two classes as follows:\n",
        "\n",
        "- Class 0: Z progression values that are below the 75th percentile of the original target variable.\n",
        "- Class 1: Z progression values that are above the 75th percentile of the original target variable.\n",
        "\n",
        "By doing this, we are creating an imbalance where Class 0 will be more prevalent than Class 1, mimicking a common scenario in real-world imbalanced datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQMA6OPsXD49"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Shuffle the data\n",
        "X, y = shuffle(X, y, random_state=42)\n",
        "\n",
        "# Create an imbalanced target variable\n",
        "y_imbalanced = np.where(y > np.percentile(y, 75), 1, 0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_imbalanced, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJiy4EyUYX93"
      },
      "source": [
        "\n",
        "**Task 2.1 (3 points):**\n",
        "- Create a SVM classifier with a linear kernel, then calculate accuracy, precision, recall, and F1 score using available library functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKLZyXkwSDw0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "099c8ebf-d74b-4a65-e5e1-5aecaf1f0740"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8426966292134831\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "### Add code here\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "svm_c=SVC(kernel='linear',random_state=42)\n",
        "svm_c.fit(X_train, y_train)\n",
        "y_pred=svm_c.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "print(\"F1:\", f1_score(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6mJ3w9TbWHT"
      },
      "source": [
        "\n",
        "**Task 2.2 (5 points):** What causes the metrics to exhibit lower values for the imbalanced dataset compared to those in homework 1?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2: It may because of the skewed distribution of classes. Classifiers tend to be biased towards majority class, resulting in poorer performance on minority class."
      ],
      "metadata": {
        "id": "tfACxaufgMtU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPYn44O40aKX"
      },
      "source": [
        "**Random oversampling** is one of the many techniques used to address the class imbalance problem. It involves increasing the number of instances in the minority class by randomly duplicating existing instances. This helps to balance the class distribution and can lead to improved performance for certain models.\n",
        "\n",
        "**Task 2.3 (2 points):** Calculate and display the following statistics for the target variable (y) before applying random oversampling:\n",
        "  - Mean\n",
        "  - Standard Deviation\n",
        "  - Minimum\n",
        "  - Maximum\n",
        "\n",
        "**Task 2.4 (5 points):** Perform random oversampling on the training set. After oversampling, calculate and display the same statistics for the oversampled target variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PItrNXNsX7ou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1522708f-f785-4f48-f184-250139b83d86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean (Oversampled): before 152.13348416289594 after: 0.5\n",
            "Standard Deviation (Oversampled): before 77.00574586945044 after: 0.5\n",
            "Minimum (Oversampled): before 25.0 after: 0\n",
            "Maximum (Oversampled): before 346.0 after: 1\n"
          ]
        }
      ],
      "source": [
        "# Apply Random Oversampling\n",
        "import numpy as np\n",
        "\n",
        "mean_y = np.mean(y)\n",
        "std_y = np.std(y)\n",
        "min_y = np.min(y)\n",
        "max_y = np.max(y)\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "\n",
        "X_train_res, y_train_res = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "mean_y_res = np.mean(y_train_res)\n",
        "std_y_res = np.std(y_train_res)\n",
        "min_y_res = np.min(y_train_res)\n",
        "max_y_res = np.max(y_train_res)\n",
        "\n",
        "print(\"Mean (Oversampled): before\", mean_y, \"after:\", mean_y_res)\n",
        "print(\"Standard Deviation (Oversampled): before\", std_y, \"after:\", std_y_res)\n",
        "print(\"Minimum (Oversampled): before\", min_y, \"after:\", min_y_res)\n",
        "print(\"Maximum (Oversampled): before\", max_y, \"after:\", max_y_res)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oel3kCeV2tOM"
      },
      "source": [
        "**Task 2.5 (5 points):**\n",
        "- Create another instance of SVM classifier with linear kernel, fit it on the oversampled data and calculate all the prior metrics for the oversampled model.\n",
        "- Show the metrics with different regularization parameters {0.1, 1, 10, 100} on the linear kernel.\n",
        "- Show the metrics with polynomial degrees {-1, 0, 3, 4} and observe how the model's complexity changes.\n",
        "- Introduce different values for the regularization parameter in the RBF kernel and show how it balances the trade-off between maximizing the margin and minimizing classification error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeictOez24d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed073cec-c4b3-4108-b775-2421626f7178"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Oversampled): 0.7752808988764045\n",
            "Precision (Oversampled): 0.40625\n",
            "Recall (Oversampled): 0.9285714285714286\n",
            "F1 Score (Oversampled): 0.5652173913043478\n",
            "\n",
            "C = 0.1\n",
            "Accuracy: 0.7415730337078652\n",
            "Precision: 0.37142857142857144\n",
            "Recall: 0.9285714285714286\n",
            "F1 Score: 0.5306122448979592\n",
            "\n",
            "C = 1\n",
            "Accuracy: 0.7752808988764045\n",
            "Precision: 0.40625\n",
            "Recall: 0.9285714285714286\n",
            "F1 Score: 0.5652173913043478\n",
            "\n",
            "C = 10\n",
            "Accuracy: 0.7865168539325843\n",
            "Precision: 0.4\n",
            "Recall: 0.7142857142857143\n",
            "F1 Score: 0.5128205128205129\n",
            "\n",
            "C = 100\n",
            "Accuracy: 0.797752808988764\n",
            "Precision: 0.4166666666666667\n",
            "Recall: 0.7142857142857143\n",
            "F1 Score: 0.5263157894736842\n",
            "\n",
            "Degree = 1\n",
            "Accuracy: 0.797752808988764\n",
            "Precision: 0.4166666666666667\n",
            "Recall: 0.7142857142857143\n",
            "F1 Score: 0.5263157894736842\n",
            "\n",
            "Degree = 0\n",
            "Accuracy: 0.15730337078651685\n",
            "Precision: 0.15730337078651685\n",
            "Recall: 1.0\n",
            "F1 Score: 0.27184466019417475\n",
            "\n",
            "Degree = 3\n",
            "Accuracy: 0.8202247191011236\n",
            "Precision: 0.45454545454545453\n",
            "Recall: 0.7142857142857143\n",
            "F1 Score: 0.5555555555555556\n",
            "\n",
            "Degree = 4\n",
            "Accuracy: 0.797752808988764\n",
            "Precision: 0.4\n",
            "Recall: 0.5714285714285714\n",
            "F1 Score: 0.47058823529411764\n",
            "\n",
            "C = 0.1\n",
            "Accuracy: 0.7752808988764045\n",
            "Precision: 0.4\n",
            "Recall: 0.8571428571428571\n",
            "F1 Score: 0.5454545454545455\n",
            "\n",
            "C = 1\n",
            "Accuracy: 0.797752808988764\n",
            "Precision: 0.4090909090909091\n",
            "Recall: 0.6428571428571429\n",
            "F1 Score: 0.5000000000000001\n",
            "\n",
            "C = 10\n",
            "Accuracy: 0.7752808988764045\n",
            "Precision: 0.35\n",
            "Recall: 0.5\n",
            "F1 Score: 0.4117647058823529\n",
            "\n",
            "C = 100\n",
            "Accuracy: 0.7303370786516854\n",
            "Precision: 0.2727272727272727\n",
            "Recall: 0.42857142857142855\n",
            "F1 Score: 0.33333333333333326\n"
          ]
        }
      ],
      "source": [
        "### Add code here\n",
        "svm_clf_res = SVC(kernel='linear', random_state=42)\n",
        "svm_clf_res.fit(X_train_res, y_train_res)\n",
        "\n",
        "y_pred_res = svm_clf_res.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy_res = accuracy_score(y_test, y_pred_res)\n",
        "precision_res = precision_score(y_test, y_pred_res)\n",
        "recall_res = recall_score(y_test, y_pred_res)\n",
        "f1_res = f1_score(y_test, y_pred_res)\n",
        "\n",
        "print(\"Accuracy (Oversampled):\", accuracy_res)\n",
        "print(\"Precision (Oversampled):\", precision_res)\n",
        "print(\"Recall (Oversampled):\", recall_res)\n",
        "print(\"F1 Score (Oversampled):\", f1_res)\n",
        "\n",
        "for C in [0.1, 1, 10, 100]:\n",
        "    svm_clf_linear = SVC(kernel='linear', C=C, random_state=42)\n",
        "    svm_clf_linear.fit(X_train_res, y_train_res)\n",
        "    y_pred_linear = svm_clf_linear.predict(X_test)\n",
        "    print(\"\\nC =\", C)\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred_linear))\n",
        "    print(\"Precision:\", precision_score(y_test, y_pred_linear))\n",
        "    print(\"Recall:\", recall_score(y_test, y_pred_linear))\n",
        "    print(\"F1 Score:\", f1_score(y_test, y_pred_linear))\n",
        "for degree in [1, 0, 3, 4]:\n",
        "    svm_clf_poly = SVC(kernel='poly', degree=degree, coef0=1, C=1, random_state=42)\n",
        "    svm_clf_poly.fit(X_train_res, y_train_res)\n",
        "    y_pred_poly = svm_clf_poly.predict(X_test)\n",
        "    print(\"\\nDegree =\", degree)\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred_poly))\n",
        "    print(\"Precision:\", precision_score(y_test, y_pred_poly))\n",
        "    print(\"Recall:\", recall_score(y_test, y_pred_poly))\n",
        "    print(\"F1 Score:\", f1_score(y_test, y_pred_poly))\n",
        "for C in [0.1, 1, 10, 100]:\n",
        "    svm_clf_rbf = SVC(kernel='rbf', C=C, random_state=42)\n",
        "    svm_clf_rbf.fit(X_train_res, y_train_res)\n",
        "    y_pred_rbf = svm_clf_rbf.predict(X_test)\n",
        "    print(\"\\nC =\", C)\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred_rbf))\n",
        "    print(\"Precision:\", precision_score(y_test, y_pred_rbf))\n",
        "    print(\"Recall:\", recall_score(y_test, y_pred_rbf))\n",
        "    print(\"F1 Score:\", f1_score(y_test, y_pred_rbf))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oquatEvqroqa"
      },
      "source": [
        "### Question 3: Naive Bayes Model (10 points)\n",
        "\n",
        "Implement the Naieve Bayes classifer on the Z dataset.\n",
        "\n",
        "We will assume that each continuous feature $X_i$ of $X$ follow a Gaussian distribution within each class $Y$.\n",
        "\n",
        "- For each class $c$, calculate the mean $(\\mu_c)$ and standard deviation $(\\sigma_c)$ for each feature. These parameters represent the central tendency and spread of the feature values within each class. They can be computed as:\n",
        "\n",
        "   \\begin{align*}\n",
        "   \\mu_c^j &= \\frac{1}{N_c} \\sum_{i=1}^{N_c} X_i^j \\quad \\text{(mean of feature \\(j\\) in class \\(c\\))} \\\\\n",
        "   \\sigma_c^j &= \\sqrt{\\frac{1}{N_c} \\sum_{i=1}^{N_c} (X_i^j - \\mu_c^j)^2} + \\epsilon \\quad \\text{(standard deviation of feature \\(j\\) in class \\(c\\))}\n",
        "   \\end{align*}\n",
        "     \n",
        "   where $N_c$ is the number of data points in class $c$, and $\\varepsilon=1e^{-6}$ is a small constant added for numerical stability.\n",
        "\n",
        "- To make a prediction for a new data point $x$, calculate the probability of $x$ belonging to each class $c$ using the Gaussian probability density function:\n",
        "\n",
        "   \\begin{align*}\n",
        "   P(X^j = x^j | Y = c) = \\frac{1}{\\sqrt{2\\pi}\\sigma_c^j} e^{-\\frac{1}{2}\\left(\\frac{x^j - \\mu_c^j}{\\sigma_c^j}\\right)^2}\n",
        "   \\end{align*}\n",
        "\n",
        "- Calculate the class probability $P(Y = c | X = x)$ as the product of the probabilities of each feature:\n",
        "\n",
        "    \\begin{align*}\n",
        "     P(Y = c | X = x) = P(Y = c) \\prod_{j=1}^{D} P(X^j = x^j | Y = c)\n",
        "    \\end{align*}\n",
        "\n",
        "   where $D$ is the number of features.\n",
        "\n",
        "- Assign the class label to the class with the highest probability:\n",
        "\n",
        "    \\begin{align*}\n",
        "     \\hat{Y} = \\arg\\max_{c} P(Y = c | X = x)\n",
        "     \\end{align*}\n",
        "\n",
        "**Hint:** In the code for Gaussian Naive Bayes, we take logarithms in certain calculations. This is a common technique used to avoid numerical underflow, especially when working with small probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEIVwXWKrscC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b846e074-3bb0-4d53-8e2d-0ae0fbd060fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.797752808988764\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class GaussianNaiveBayes:\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.classes = np.unique(y)\n",
        "        self.parameters = {}\n",
        "        for c in self.classes:\n",
        "          X_c=X[y==c]\n",
        "          self.parameters[c]={\n",
        "              \"mean\": X_c.mean(axis=0),\n",
        "              \"std\": np.sqrt(X_c.var(axis=0)+1e-6)\n",
        "          }\n",
        "\n",
        "\n",
        "    def _calculate_likelihood(self, x, mean, std):\n",
        "      ex=np.exp(-0.5*((x - mean)/std)**2)\n",
        "      return (1/(np.sqrt(2*np.pi)*std))*ex\n",
        "\n",
        "    def _calculate_class_probability(self, x, c):\n",
        "      likeli=self._calculate_likelihood(x, self.parameters[c][\"mean\"], self.parameters[c][\"std\"])\n",
        "      return np.sum(np.log(likeli))\n",
        "\n",
        "    def predict(self, X):\n",
        "      predictions = []\n",
        "      for x in X:\n",
        "        class_probabilities = {c: self._calculate_class_probability(x, c) for c in self.classes}\n",
        "        predictions.append(max(class_probabilities, key=class_probabilities.get))\n",
        "      return np.array(predictions)\n",
        "        ### Code for predicting the class label\n",
        "\n",
        "    def score(self, X, y):\n",
        "        y_pred = self.predict(X)\n",
        "        accuracy = np.mean(y_pred == y)\n",
        "        return accuracy\n",
        "\n",
        "# Initialize and train the Gaussian Naive Bayes classifier\n",
        "gnb = GaussianNaiveBayes()\n",
        "gnb.fit(X_train, y_train)\n",
        "y_pred = gnb.predict(X_test)\n",
        "accuracy = gnb.score(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4czskeTTCMam"
      },
      "source": [
        "### Question 4: ROC curve and AUROC (15 points)\n",
        "\n",
        "**Task 4.1 (3 points):** Imagine you are a public health researcher investigating the performance of a new diagnostic test for disease Z, which is a potentially life-threatening condition. The test is designed to identify individuals who have the disease. You have collected data from a group of 500 patients who were tested for disease Z, and the results are as follows:\n",
        "\n",
        "Out of 150 patients who actually have disease Z, the test correctly identified 120 of them as positive.\n",
        "However, the test also falsely identified 50 patients who do not have disease Z as positive.\n",
        "\n",
        "* **Precision:** Define precision in the context of this diagnostic test for disease Z. Calculate the precision of the test based on the provided data.\n",
        "* **Recall:** Explain what recall means in this scenario. Calculate the recall of the test based on the provided data.\n",
        "* **F1-score:** Define the F1-score and explain why it is important, especially in the context of diagnosing a serious disease like Z. Calculate the F1-score of the test based on the provided data.\n",
        "* **Specificity:** What is specificity, and why is it relevant when evaluating a diagnostic test like this one? Calculate the specificity of the test based on the provided data.\n",
        "* **Balanced Accuracy:** Describe what balanced accuracy is and why it might be a useful metric in this situation. Calculate the balanced accuracy of the test based on the provided data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.1\n",
        "\n",
        "Precision: Proportion of patients that are correctly identified as having disease out of all who test positive. =120/(120+50)=0.7059\n",
        "\n",
        "Recall: ability of diagnostic test to correctly identify the disease. =120/(120+30)=0.8\n",
        "\n",
        "F1:Harmonic mean of precision and recall, important because it balances the trade-off between precision and recall, providing more holistic evaluation. = 2(0.7059*0.8)/(0.7059+0.8)=0.7493\n",
        "\n",
        "Specificity: It measures the ability of the test to correctly identify patients without disease. In this case, it's crucial to minimize false positive to avoid unnecessary treatment. =300/(300+50)=0.8571\n",
        "\n",
        "Balanced Accuracy: it computes the average of recall and true negative rate. Useful when classes are imbalanced as it ensures errors are taken into account. =(0.8+0.8571)/2=0.8286"
      ],
      "metadata": {
        "id": "5JnjKrM2-H8y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPOZo4QM5V_y"
      },
      "source": [
        "**Task 4.2 (6 Points)** Plot the ROC curve\n",
        "\n",
        "An ROC curve plots TPR (y-axis) vs. FPR (x-axis) at all classification thresholds. Lowering the classification threshold classifies more items as positive, thus increasing both False Positives and True Positives.\n",
        "\n",
        "See this for more details (https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)\n",
        "\n",
        "Plot the ROC curve for Disease Z HW1 dataset with SVM classifier. **Note that you are not allowed to use any library function to compute the ROC. You have to do it from scratch.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZnZs_QC5oxQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "69ba94e7-777b-4969-cb7b-d14e44b12b19"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "## Your code to compute and plot ROC goes here\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "\n",
        "clf = svm.SVC(kernel='linear', C=1, probability=True)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_scores = clf.decision_function(X_test)\n",
        "\n",
        "thresholds = np.sort(y_scores)\n",
        "tpr = []\n",
        "fpr = []\n",
        "\n",
        "for threshold in thresholds:\n",
        "    y_p = (y_scores > threshold).astype(int)\n",
        "    TP = np.sum((y_p == 1) & (y_test == 1))\n",
        "    FP = np.sum((y_p == 1) & (y_test == 0))\n",
        "    FN = np.sum((y_p == 0) & (y_test == 1))\n",
        "    TN = np.sum((y_p == 0) & (y_test == 0))\n",
        "    tpr.append(TP / (TP + FN))\n",
        "    fpr.append(FP / (FP + TN))\n",
        "\n",
        "plt.plot(fpr, tpr, marker='.')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9sRjUMk592y"
      },
      "source": [
        "**Task 4.3 (6 Points):** Compute the AUC of ROC\n",
        "\n",
        "AUC stands for \"Area under the ROC Curve.\" That is, AUC measures the entire two-dimensional area underneath the entire ROC curve (think integral calculus) from (0,0) to (1,1). AUC provides an aggregate measure of performance across all possible classification thresholds. One way of interpreting AUC is as the probability that the model ranks a random positive example more highly than a random negative example.\n",
        "\n",
        "Compute the AUC of your SVM model. **Note that you are not allowed to use any library function to compute the AUC. You have to do it from scratch.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOBw8ACA587S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "362491bc-357f-4d53-c6a1-7daf2309265b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 0.8647619047619047\n"
          ]
        }
      ],
      "source": [
        "sorted_points = sorted(zip(fpr, tpr))\n",
        "fpr_sorted, tpr_sorted = zip(*sorted_points)\n",
        "\n",
        "auc = 0.0\n",
        "for i in range(1, len(fpr_sorted)):\n",
        "    h = fpr_sorted[i] - fpr_sorted[i - 1]\n",
        "    b1 = tpr_sorted[i - 1]\n",
        "    b2 = tpr_sorted[i]\n",
        "    auc += 0.5 * (b1 + b2) * h\n",
        "\n",
        "print(f\"AUC: {auc}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}